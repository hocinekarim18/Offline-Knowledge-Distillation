{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4976fd",
   "metadata": {},
   "source": [
    "## BibiliothÃ¨que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da05cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 10:15:32.825740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-06 10:15:32.825774: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from resnet import resnet_layer, resnet_v1\n",
    "from Distiller import Distiller_AdaIn, Distiller\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "seed = tf.random.set_seed(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59d199",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ab2228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_hist_kd(hist, figname):\n",
    "    #History\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(hist.history['sparse_categorical_accuracy'], label = \"train accur\")\n",
    "    plt.plot(hist.history['val_sparse_categorical_accuracy'], label = \"Val accur\")\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(hist.history['student_loss'], label = \"student Loss\")\n",
    "    plt.plot(hist.history['val_student_loss'], label = \"Val loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Student Loss')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(figname)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8cf7b",
   "metadata": {},
   "source": [
    "## Loading cifar10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2339918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Data Loading ================\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "y_test shape: (10000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"================ Data Loading ================\")\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Data shapes\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac01f4",
   "metadata": {},
   "source": [
    "## Loading Resnet26 Teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a345a505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Loading teacher model ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 10:16:00.624759: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-06 10:16:00.624825: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-06 10:16:00.624882: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tall12): /proc/driver/nvidia/version does not exist\n",
      "2022-05-06 10:16:00.628015: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Teacher model!\n",
      "313/313 [==============================] - 14s 39ms/step - loss: 0.5328 - sparse_categorical_accuracy: 0.9054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"================ Loading teacher model ================\")\n",
    "teacher = tf.keras.models.load_model(\"Resnet26_from_logits\")\n",
    "print(\"Evaluation of Teacher model!\")\n",
    "teacher.evaluate(x_test, y_test)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978ef20",
   "metadata": {},
   "source": [
    "## Creating a data augmentation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097a558e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Building dataGen ================\n"
     ]
    }
   ],
   "source": [
    "print(\"================ Building dataGen ================\")\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d738c",
   "metadata": {},
   "source": [
    "## Building a preprocessing routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec9d02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ============== Adding preprocessing layers ===============\n"
     ]
    }
   ],
   "source": [
    "print(\" ============== Adding preprocessing layers ===============\")\n",
    "preprocessing = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomCrop(32, 32, seed= seed),\n",
    "    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed= seed),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66b092",
   "metadata": {},
   "source": [
    "## Building Resnet8 Student model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d168fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Building Student Network Resnet8 ! =============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"============== Building Student Network Resnet8 ! =============\")\n",
    "\n",
    "student = resnet_v1(input_shape=(32, 32, 3), depth= 8)\n",
    "\n",
    "student = tf.keras.Sequential([\n",
    "    preprocessing,\n",
    "    student,   \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "student_scratch = tf.keras.models.clone_model(student)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3265cc",
   "metadata": {},
   "source": [
    "## Building callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0c96cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_save = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/callback/callback_save\",\n",
    "    monitor='val_student_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    "    options=None,\n",
    "    initial_value_threshold=None,\n",
    ")\n",
    "\n",
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_student_loss',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    \n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.000001,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b3cc5",
   "metadata": {},
   "source": [
    "## Knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb7877f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "A = [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "lr = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc06aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1562/1562 [==============================] - 105s 65ms/step - sparse_categorical_accuracy: 0.4569 - student_loss: 2.0946 - loss: 1.2131 - val_sparse_categorical_accuracy: 0.4717 - val_student_loss: 2.6400 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "1562/1562 [==============================] - 98s 63ms/step - sparse_categorical_accuracy: 0.6227 - student_loss: 1.7494 - loss: 0.8685 - val_sparse_categorical_accuracy: 0.5996 - val_student_loss: 2.4348 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "1562/1562 [==============================] - 97s 62ms/step - sparse_categorical_accuracy: 0.6764 - student_loss: 1.5335 - loss: 0.7380 - val_sparse_categorical_accuracy: 0.6163 - val_student_loss: 1.4725 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "1562/1562 [==============================] - 92s 59ms/step - sparse_categorical_accuracy: 0.7121 - student_loss: 1.3828 - loss: 0.6522 - val_sparse_categorical_accuracy: 0.6668 - val_student_loss: 1.4037 - lr: 0.1000\n",
      "Epoch 5/100\n",
      "1562/1562 [==============================] - 75s 48ms/step - sparse_categorical_accuracy: 0.7448 - student_loss: 1.2500 - loss: 0.5831 - val_sparse_categorical_accuracy: 0.7294 - val_student_loss: 1.4264 - lr: 0.1000\n",
      "Epoch 6/100\n",
      "1562/1562 [==============================] - 73s 46ms/step - sparse_categorical_accuracy: 0.7682 - student_loss: 1.1552 - loss: 0.5301 - val_sparse_categorical_accuracy: 0.7347 - val_student_loss: 1.3172 - lr: 0.1000\n",
      "Epoch 7/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.7829 - student_loss: 1.0767 - loss: 0.4940 - val_sparse_categorical_accuracy: 0.7487 - val_student_loss: 1.3333 - lr: 0.1000\n",
      "Epoch 8/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.7983 - student_loss: 1.0024 - loss: 0.4579 - val_sparse_categorical_accuracy: 0.7316 - val_student_loss: 1.4207 - lr: 0.1000\n",
      "Epoch 9/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8084 - student_loss: 0.9549 - loss: 0.4376 - val_sparse_categorical_accuracy: 0.7814 - val_student_loss: 1.3753 - lr: 0.1000\n",
      "Epoch 10/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8177 - student_loss: 0.8933 - loss: 0.4099 - val_sparse_categorical_accuracy: 0.7391 - val_student_loss: 1.4116 - lr: 0.1000\n",
      "Epoch 11/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.8237 - student_loss: 0.8510 - loss: 0.3946 - val_sparse_categorical_accuracy: 0.7793 - val_student_loss: 1.4026 - lr: 0.1000\n",
      "Epoch 12/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.8340 - student_loss: 0.8126 - loss: 0.3770 - val_sparse_categorical_accuracy: 0.7842 - val_student_loss: 1.3128 - lr: 0.1000\n",
      "Epoch 13/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.8402 - student_loss: 0.7702 - loss: 0.3601 - val_sparse_categorical_accuracy: 0.7788 - val_student_loss: 1.4246 - lr: 0.1000\n",
      "Epoch 14/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.8471 - student_loss: 0.7437 - loss: 0.3499 - val_sparse_categorical_accuracy: 0.7951 - val_student_loss: 1.3382 - lr: 0.1000\n",
      "Epoch 15/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.8514 - student_loss: 0.7069 - loss: 0.3371 - val_sparse_categorical_accuracy: 0.7653 - val_student_loss: 1.3375 - lr: 0.1000\n",
      "Epoch 16/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.8548 - student_loss: 0.6772 - loss: 0.3260 - val_sparse_categorical_accuracy: 0.7939 - val_student_loss: 1.4053 - lr: 0.1000\n",
      "Epoch 17/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.8620 - student_loss: 0.6541 - loss: 0.3158 - val_sparse_categorical_accuracy: 0.7941 - val_student_loss: 1.3339 - lr: 0.1000\n",
      "Epoch 18/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8627 - student_loss: 0.6306 - loss: 0.3076 - val_sparse_categorical_accuracy: 0.7959 - val_student_loss: 1.4841 - lr: 0.1000\n",
      "Epoch 19/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8682 - student_loss: 0.6077 - loss: 0.3002 - val_sparse_categorical_accuracy: 0.8053 - val_student_loss: 1.4669 - lr: 0.1000\n",
      "Epoch 20/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.8727 - student_loss: 0.5793 - loss: 0.2892 - val_sparse_categorical_accuracy: 0.7930 - val_student_loss: 1.4044 - lr: 0.1000\n",
      "Epoch 21/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8776 - student_loss: 0.5491 - loss: 0.2799 - val_sparse_categorical_accuracy: 0.8268 - val_student_loss: 1.4556 - lr: 0.1000\n",
      "Epoch 22/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.8791 - student_loss: 0.5381 - loss: 0.2753 - val_sparse_categorical_accuracy: 0.8051 - val_student_loss: 1.2149 - lr: 0.1000\n",
      "Epoch 23/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8827 - student_loss: 0.5224 - loss: 0.2695 - val_sparse_categorical_accuracy: 0.8157 - val_student_loss: 1.3181 - lr: 0.1000\n",
      "Epoch 24/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8863 - student_loss: 0.4967 - loss: 0.2616 - val_sparse_categorical_accuracy: 0.8186 - val_student_loss: 1.2949 - lr: 0.1000\n",
      "Epoch 25/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8887 - student_loss: 0.4758 - loss: 0.2554 - val_sparse_categorical_accuracy: 0.7825 - val_student_loss: 1.3693 - lr: 0.1000\n",
      "Epoch 26/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8928 - student_loss: 0.4648 - loss: 0.2512 - val_sparse_categorical_accuracy: 0.8198 - val_student_loss: 1.3413 - lr: 0.1000\n",
      "Epoch 27/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.8946 - student_loss: 0.4564 - loss: 0.2472 - val_sparse_categorical_accuracy: 0.7794 - val_student_loss: 1.3431 - lr: 0.1000\n",
      "Epoch 28/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.8960 - student_loss: 0.4404 - loss: 0.2425 - val_sparse_categorical_accuracy: 0.8251 - val_student_loss: 1.3690 - lr: 0.1000\n",
      "Epoch 29/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.9001 - student_loss: 0.4184 - loss: 0.2353 - val_sparse_categorical_accuracy: 0.8218 - val_student_loss: 1.3873 - lr: 0.1000\n",
      "Epoch 30/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.9013 - student_loss: 0.4090 - loss: 0.2324 - val_sparse_categorical_accuracy: 0.8093 - val_student_loss: 1.3266 - lr: 0.1000\n",
      "Epoch 31/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9035 - student_loss: 0.4079 - loss: 0.2318 - val_sparse_categorical_accuracy: 0.8278 - val_student_loss: 1.3251 - lr: 0.1000\n",
      "Epoch 32/100\n",
      "1563/1562 [==============================] - ETA: 0s - sparse_categorical_accuracy: 0.9064 - student_loss: 0.3850 - loss: 0.2250\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9064 - student_loss: 0.3851 - loss: 0.2250 - val_sparse_categorical_accuracy: 0.8303 - val_student_loss: 1.3954 - lr: 0.1000\n",
      "Epoch 33/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9312 - student_loss: 0.2615 - loss: 0.1813 - val_sparse_categorical_accuracy: 0.8507 - val_student_loss: 1.3277 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.9380 - student_loss: 0.2313 - loss: 0.1693 - val_sparse_categorical_accuracy: 0.8532 - val_student_loss: 1.2650 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9415 - student_loss: 0.2171 - loss: 0.1641 - val_sparse_categorical_accuracy: 0.8514 - val_student_loss: 1.2847 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9433 - student_loss: 0.2087 - loss: 0.1616 - val_sparse_categorical_accuracy: 0.8533 - val_student_loss: 1.2773 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9436 - student_loss: 0.2048 - loss: 0.1606 - val_sparse_categorical_accuracy: 0.8516 - val_student_loss: 1.2773 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.9464 - student_loss: 0.1923 - loss: 0.1578 - val_sparse_categorical_accuracy: 0.8520 - val_student_loss: 1.3199 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.9474 - student_loss: 0.1915 - loss: 0.1565 - val_sparse_categorical_accuracy: 0.8516 - val_student_loss: 1.3302 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "1562/1562 [==============================] - 74s 47ms/step - sparse_categorical_accuracy: 0.9489 - student_loss: 0.1826 - loss: 0.1544 - val_sparse_categorical_accuracy: 0.8515 - val_student_loss: 1.3114 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.9476 - student_loss: 0.1864 - loss: 0.1546 - val_sparse_categorical_accuracy: 0.8502 - val_student_loss: 1.3129 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "1562/1562 [============================>.] - ETA: 0s - sparse_categorical_accuracy: 0.9483 - student_loss: 0.1793 - loss: 0.1528\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1562/1562 [==============================] - 71s 45ms/step - sparse_categorical_accuracy: 0.9483 - student_loss: 0.1800 - loss: 0.1529 - val_sparse_categorical_accuracy: 0.8509 - val_student_loss: 1.3077 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.9511 - student_loss: 0.1688 - loss: 0.1496 - val_sparse_categorical_accuracy: 0.8525 - val_student_loss: 1.3075 - lr: 1.0000e-03\n",
      "Epoch 44/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9518 - student_loss: 0.1664 - loss: 0.1488 - val_sparse_categorical_accuracy: 0.8523 - val_student_loss: 1.3146 - lr: 1.0000e-03\n",
      "Epoch 45/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9510 - student_loss: 0.1671 - loss: 0.1490 - val_sparse_categorical_accuracy: 0.8520 - val_student_loss: 1.3088 - lr: 1.0000e-03\n",
      "Epoch 46/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.9523 - student_loss: 0.1638 - loss: 0.1474 - val_sparse_categorical_accuracy: 0.8508 - val_student_loss: 1.3023 - lr: 1.0000e-03\n",
      "Epoch 47/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9521 - student_loss: 0.1653 - loss: 0.1475 - val_sparse_categorical_accuracy: 0.8514 - val_student_loss: 1.2936 - lr: 1.0000e-03\n",
      "Epoch 48/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9532 - student_loss: 0.1647 - loss: 0.1477 - val_sparse_categorical_accuracy: 0.8520 - val_student_loss: 1.2996 - lr: 1.0000e-03\n",
      "Epoch 49/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9528 - student_loss: 0.1629 - loss: 0.1475 - val_sparse_categorical_accuracy: 0.8515 - val_student_loss: 1.2977 - lr: 1.0000e-03\n",
      "Epoch 50/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9528 - student_loss: 0.1639 - loss: 0.1473 - val_sparse_categorical_accuracy: 0.8520 - val_student_loss: 1.2950 - lr: 1.0000e-03\n",
      "Epoch 51/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9524 - student_loss: 0.1645 - loss: 0.1469 - val_sparse_categorical_accuracy: 0.8504 - val_student_loss: 1.2972 - lr: 1.0000e-03\n",
      "Epoch 52/100\n",
      "1562/1562 [============================>.] - ETA: 0s - sparse_categorical_accuracy: 0.9519 - student_loss: 0.1667 - loss: 0.1483\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.9519 - student_loss: 0.1665 - loss: 0.1482 - val_sparse_categorical_accuracy: 0.8514 - val_student_loss: 1.3028 - lr: 1.0000e-03\n",
      "Epoch 53/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9525 - student_loss: 0.1644 - loss: 0.1472 - val_sparse_categorical_accuracy: 0.8514 - val_student_loss: 1.3001 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9533 - student_loss: 0.1626 - loss: 0.1468 - val_sparse_categorical_accuracy: 0.8513 - val_student_loss: 1.2980 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9534 - student_loss: 0.1622 - loss: 0.1466 - val_sparse_categorical_accuracy: 0.8526 - val_student_loss: 1.3025 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.9515 - student_loss: 0.1696 - loss: 0.1487 - val_sparse_categorical_accuracy: 0.8521 - val_student_loss: 1.2997 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1562/1562 [==============================] - 71s 46ms/step - sparse_categorical_accuracy: 0.9523 - student_loss: 0.1643 - loss: 0.1475 - val_sparse_categorical_accuracy: 0.8526 - val_student_loss: 1.3025 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9532 - student_loss: 0.1578 - loss: 0.1462 - val_sparse_categorical_accuracy: 0.8527 - val_student_loss: 1.2980 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.9526 - student_loss: 0.1656 - loss: 0.1478 - val_sparse_categorical_accuracy: 0.8521 - val_student_loss: 1.2950 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.9528 - student_loss: 0.1627 - loss: 0.1464 - val_sparse_categorical_accuracy: 0.8519 - val_student_loss: 1.3045 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9527 - student_loss: 0.1588 - loss: 0.1461 - val_sparse_categorical_accuracy: 0.8531 - val_student_loss: 1.3028 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "1562/1562 [============================>.] - ETA: 0s - sparse_categorical_accuracy: 0.9533 - student_loss: 0.1620 - loss: 0.1467\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9533 - student_loss: 0.1618 - loss: 0.1466 - val_sparse_categorical_accuracy: 0.8516 - val_student_loss: 1.3009 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9511 - student_loss: 0.1637 - loss: 0.1471 - val_sparse_categorical_accuracy: 0.8524 - val_student_loss: 1.3040 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "1562/1562 [==============================] - 73s 46ms/step - sparse_categorical_accuracy: 0.9541 - student_loss: 0.1624 - loss: 0.1468 - val_sparse_categorical_accuracy: 0.8518 - val_student_loss: 1.3038 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.9533 - student_loss: 0.1594 - loss: 0.1466 - val_sparse_categorical_accuracy: 0.8517 - val_student_loss: 1.2969 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9536 - student_loss: 0.1606 - loss: 0.1461 - val_sparse_categorical_accuracy: 0.8522 - val_student_loss: 1.3020 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9533 - student_loss: 0.1651 - loss: 0.1485 - val_sparse_categorical_accuracy: 0.8517 - val_student_loss: 1.2968 - lr: 1.0000e-05\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9533 - student_loss: 0.1625 - loss: 0.1470 - val_sparse_categorical_accuracy: 0.8511 - val_student_loss: 1.3031 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.9537 - student_loss: 0.1612 - loss: 0.1464 - val_sparse_categorical_accuracy: 0.8521 - val_student_loss: 1.3048 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.9529 - student_loss: 0.1610 - loss: 0.1469 - val_sparse_categorical_accuracy: 0.8528 - val_student_loss: 1.3034 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1562/1562 [==============================] - 73s 47ms/step - sparse_categorical_accuracy: 0.9527 - student_loss: 0.1625 - loss: 0.1476 - val_sparse_categorical_accuracy: 0.8519 - val_student_loss: 1.3039 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1562/1562 [============================>.] - ETA: 0s - sparse_categorical_accuracy: 0.9539 - student_loss: 0.1578 - loss: 0.1456\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9539 - student_loss: 0.1581 - loss: 0.1457 - val_sparse_categorical_accuracy: 0.8527 - val_student_loss: 1.2969 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1562/1562 [==============================] - 72s 46ms/step - sparse_categorical_accuracy: 0.9522 - student_loss: 0.1646 - loss: 0.1474 - val_sparse_categorical_accuracy: 0.8528 - val_student_loss: 1.2966 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "1123/1562 [====================>.........] - ETA: 19s - sparse_categorical_accuracy: 0.9541 - student_loss: 0.1609 - loss: 0.1473"
     ]
    }
   ],
   "source": [
    "for a in A:\n",
    "    # Configuration du tensorboard\n",
    "    NAME = f\"Resnet8_kd_alpha_{a}_temp_{5}\"\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir = f\"logs/{NAME}\", \n",
    "                                                 histogram_freq = 1)\n",
    "    \n",
    "    student = resnet_v1(input_shape=(32, 32, 3), depth= 8)\n",
    "    student = tf.keras.Sequential([\n",
    "        preprocessing,\n",
    "        student,   \n",
    "    ])\n",
    "\n",
    "    dist = Distiller(teacher, student)\n",
    "\n",
    "    dist.compile(\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9),\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "        distillation_loss_fn = tf.keras.losses.KLDivergence(),\n",
    "        student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        alpha = a,\n",
    "        temperature = 5)\n",
    "\n",
    "    # Train and evaluate on data.\n",
    "    hist = dist.fit(x_train, y_train, \n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          steps_per_epoch = len(x_train)/BATCH_SIZE,\n",
    "          validation_data =(x_test, y_test),\n",
    "          workers =40,\n",
    "          use_multiprocessing= True,\n",
    "          callbacks = [lr_reduce, tensorboard],\n",
    "          )\n",
    "\n",
    "\n",
    "    dist.evaluate(x_test, y_test)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\" =============== History Plot ===============\")\n",
    "    plot_hist_kd(hist, f\"Resnet8_KD_notebook_alpha{a}.png\")\n",
    "\n",
    "\n",
    "    print(\"Saving model \")\n",
    "    student.save(f\"Resnet8_KD_notebook_alpha{a}\")\n",
    "    print(\"Saving Done !\")\n",
    "\n",
    "    print(\"Saving Weights \")\n",
    "    student.save_weights(f\"w_resnet8_alpha_{a}.h5\")\n",
    "    print(\"Saving Done !\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"End !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784258b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
