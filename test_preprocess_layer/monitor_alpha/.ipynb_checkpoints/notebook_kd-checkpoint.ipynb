{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4976fd",
   "metadata": {},
   "source": [
    "## Bibilioth√®que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2da05cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from resnet import resnet_layer, resnet_v1, resnet_v2\n",
    "from Distiller import Distiller_AdaIn, Distiller\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "seed = tf.random.set_seed(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59d199",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ab2228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_hist_kd(hist, figname):\n",
    "    #History\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(hist.history['sparse_categorical_accuracy'], label = \"train accur\")\n",
    "    plt.plot(hist.history['val_sparse_categorical_accuracy'], label = \"Val accur\")\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(hist.history['student_loss'], label = \"student Loss\")\n",
    "    plt.plot(hist.history['val_student_loss'], label = \"Val loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Student Loss')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(figname)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8cf7b",
   "metadata": {},
   "source": [
    "## Loading cifar10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2339918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Data Loading ================\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "y_test shape: (10000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"================ Data Loading ================\")\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Data shapes\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac01f4",
   "metadata": {},
   "source": [
    "## Loading Resnet26 Teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a345a505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Loading teacher model ================\n",
      "Evaluation of Teacher model!\n",
      "313/313 [==============================] - 12s 36ms/step - loss: 0.5328 - sparse_categorical_accuracy: 0.9054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"================ Loading teacher model ================\")\n",
    "teacher = tf.keras.models.load_model(\"Resnet26_from_logits\")\n",
    "print(\"Evaluation of Teacher model!\")\n",
    "teacher.evaluate(x_test, y_test)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978ef20",
   "metadata": {},
   "source": [
    "## Creating a data augmentation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "097a558e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Building dataGen ================\n"
     ]
    }
   ],
   "source": [
    "print(\"================ Building dataGen ================\")\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d738c",
   "metadata": {},
   "source": [
    "## Building a preprocessing routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec9d02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ============== Adding preprocessing layers ===============\n"
     ]
    }
   ],
   "source": [
    "print(\" ============== Adding preprocessing layers ===============\")\n",
    "preprocessing = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomCrop(32, 32, seed= seed),\n",
    "    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed= seed),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66b092",
   "metadata": {},
   "source": [
    "## Building Resnet8 Student model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d168fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Building Student Network Resnet8 ! =============\n"
     ]
    }
   ],
   "source": [
    "print(\"============== Building Student Network Resnet8 ! =============\")\n",
    "\n",
    "student = resnet_v1(input_shape=(32, 32, 3), depth= 8)\n",
    "\n",
    "student = tf.keras.Sequential([\n",
    "    preprocessing,\n",
    "    student,   \n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3265cc",
   "metadata": {},
   "source": [
    "## Building callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e0c96cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_save = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/callback/callback_save\",\n",
    "    monitor='val_student_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    "    options=None,\n",
    "    initial_value_threshold=None,\n",
    ")\n",
    "\n",
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_student_loss',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    \n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.000001,\n",
    ")\n",
    "\n",
    "lr_reduce2 = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    \n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.000001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3776d",
   "metadata": {},
   "source": [
    "## Scratch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fc6294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_scratch = resnet_v2(input_shape=(32, 32, 3), depth= 8)\n",
    "\n",
    "student_scratch = tf.keras.Sequential([\n",
    "    preprocessing,\n",
    "    student_scratch,   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a7d2f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1562/1562 [==============================] - 67s 42ms/step - loss: 1.5425 - sparse_categorical_accuracy: 0.4631 - val_loss: 1.7388 - val_sparse_categorical_accuracy: 0.4576 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 1.1807 - sparse_categorical_accuracy: 0.6211 - val_loss: 1.5586 - val_sparse_categorical_accuracy: 0.5302 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 1.0570 - sparse_categorical_accuracy: 0.6792 - val_loss: 1.2742 - val_sparse_categorical_accuracy: 0.6241 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.9827 - sparse_categorical_accuracy: 0.7150 - val_loss: 1.3615 - val_sparse_categorical_accuracy: 0.5867 - lr: 0.1000\n",
      "Epoch 5/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.9470 - sparse_categorical_accuracy: 0.7359 - val_loss: 1.3598 - val_sparse_categorical_accuracy: 0.5972 - lr: 0.1000\n",
      "Epoch 6/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.9235 - sparse_categorical_accuracy: 0.7484 - val_loss: 1.1282 - val_sparse_categorical_accuracy: 0.6840 - lr: 0.1000\n",
      "Epoch 7/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.9033 - sparse_categorical_accuracy: 0.7585 - val_loss: 0.9702 - val_sparse_categorical_accuracy: 0.7305 - lr: 0.1000\n",
      "Epoch 8/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8899 - sparse_categorical_accuracy: 0.7682 - val_loss: 1.7872 - val_sparse_categorical_accuracy: 0.5556 - lr: 0.1000\n",
      "Epoch 9/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8856 - sparse_categorical_accuracy: 0.7708 - val_loss: 1.3338 - val_sparse_categorical_accuracy: 0.6364 - lr: 0.1000\n",
      "Epoch 10/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.8764 - sparse_categorical_accuracy: 0.7758 - val_loss: 1.2682 - val_sparse_categorical_accuracy: 0.6843 - lr: 0.1000\n",
      "Epoch 11/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.8747 - sparse_categorical_accuracy: 0.7788 - val_loss: 1.3861 - val_sparse_categorical_accuracy: 0.6145 - lr: 0.1000\n",
      "Epoch 12/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8703 - sparse_categorical_accuracy: 0.7812 - val_loss: 1.1679 - val_sparse_categorical_accuracy: 0.6866 - lr: 0.1000\n",
      "Epoch 13/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8680 - sparse_categorical_accuracy: 0.7843 - val_loss: 1.1782 - val_sparse_categorical_accuracy: 0.6919 - lr: 0.1000\n",
      "Epoch 14/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8602 - sparse_categorical_accuracy: 0.7856 - val_loss: 1.0209 - val_sparse_categorical_accuracy: 0.7428 - lr: 0.1000\n",
      "Epoch 15/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8630 - sparse_categorical_accuracy: 0.7862 - val_loss: 1.0081 - val_sparse_categorical_accuracy: 0.7349 - lr: 0.1000\n",
      "Epoch 16/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8528 - sparse_categorical_accuracy: 0.7893 - val_loss: 1.2626 - val_sparse_categorical_accuracy: 0.6638 - lr: 0.1000\n",
      "Epoch 17/100\n",
      "1563/1562 [==============================] - ETA: 0s - loss: 0.8535 - sparse_categorical_accuracy: 0.7945\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8535 - sparse_categorical_accuracy: 0.7945 - val_loss: 1.1233 - val_sparse_categorical_accuracy: 0.7113 - lr: 0.1000\n",
      "Epoch 18/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.6842 - sparse_categorical_accuracy: 0.8481 - val_loss: 0.7108 - val_sparse_categorical_accuracy: 0.8376 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.6151 - sparse_categorical_accuracy: 0.8683 - val_loss: 0.6801 - val_sparse_categorical_accuracy: 0.8441 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5771 - sparse_categorical_accuracy: 0.8768 - val_loss: 0.6618 - val_sparse_categorical_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "1562/1562 [==============================] - 65s 41ms/step - loss: 0.5493 - sparse_categorical_accuracy: 0.8808 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.8373 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5255 - sparse_categorical_accuracy: 0.8844 - val_loss: 0.6455 - val_sparse_categorical_accuracy: 0.8405 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5026 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.8429 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.4838 - sparse_categorical_accuracy: 0.8939 - val_loss: 0.6290 - val_sparse_categorical_accuracy: 0.8426 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.8968 - val_loss: 0.6381 - val_sparse_categorical_accuracy: 0.8415 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.4534 - sparse_categorical_accuracy: 0.9002 - val_loss: 0.6091 - val_sparse_categorical_accuracy: 0.8460 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.4413 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.8395 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.4269 - sparse_categorical_accuracy: 0.9035 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.8372 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.4208 - sparse_categorical_accuracy: 0.9022 - val_loss: 0.6532 - val_sparse_categorical_accuracy: 0.8336 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.4131 - sparse_categorical_accuracy: 0.9044 - val_loss: 0.6127 - val_sparse_categorical_accuracy: 0.8398 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.4050 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.6602 - val_sparse_categorical_accuracy: 0.8275 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3946 - sparse_categorical_accuracy: 0.9100 - val_loss: 0.6019 - val_sparse_categorical_accuracy: 0.8425 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3909 - sparse_categorical_accuracy: 0.9086 - val_loss: 0.6445 - val_sparse_categorical_accuracy: 0.8287 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3857 - sparse_categorical_accuracy: 0.9094 - val_loss: 0.6825 - val_sparse_categorical_accuracy: 0.8226 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3836 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.8380 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3783 - sparse_categorical_accuracy: 0.9106 - val_loss: 0.6204 - val_sparse_categorical_accuracy: 0.8349 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.3780 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.6300 - val_sparse_categorical_accuracy: 0.8274 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3735 - sparse_categorical_accuracy: 0.9117 - val_loss: 0.6517 - val_sparse_categorical_accuracy: 0.8244 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3742 - sparse_categorical_accuracy: 0.9106 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.8268 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3692 - sparse_categorical_accuracy: 0.9137 - val_loss: 0.6174 - val_sparse_categorical_accuracy: 0.8402 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3679 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.8186 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "1563/1562 [==============================] - ETA: 0s - loss: 0.3649 - sparse_categorical_accuracy: 0.9145\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3649 - sparse_categorical_accuracy: 0.9145 - val_loss: 0.7343 - val_sparse_categorical_accuracy: 0.8093 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3077 - sparse_categorical_accuracy: 0.9370 - val_loss: 0.5747 - val_sparse_categorical_accuracy: 0.8521 - lr: 1.0000e-03\n",
      "Epoch 44/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2853 - sparse_categorical_accuracy: 0.9467 - val_loss: 0.5716 - val_sparse_categorical_accuracy: 0.8538 - lr: 1.0000e-03\n",
      "Epoch 45/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2763 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.5658 - val_sparse_categorical_accuracy: 0.8557 - lr: 1.0000e-03\n",
      "Epoch 46/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2667 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.8542 - lr: 1.0000e-03\n",
      "Epoch 47/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.5708 - val_sparse_categorical_accuracy: 0.8566 - lr: 1.0000e-03\n",
      "Epoch 48/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2584 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.5731 - val_sparse_categorical_accuracy: 0.8576 - lr: 1.0000e-03\n",
      "Epoch 49/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2525 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.5755 - val_sparse_categorical_accuracy: 0.8545 - lr: 1.0000e-03\n",
      "Epoch 50/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2509 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.5786 - val_sparse_categorical_accuracy: 0.8548 - lr: 1.0000e-03\n",
      "Epoch 51/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2466 - sparse_categorical_accuracy: 0.9602 - val_loss: 0.5742 - val_sparse_categorical_accuracy: 0.8559 - lr: 1.0000e-03\n",
      "Epoch 52/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2423 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.5723 - val_sparse_categorical_accuracy: 0.8562 - lr: 1.0000e-03\n",
      "Epoch 53/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2400 - sparse_categorical_accuracy: 0.9621 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.8549 - lr: 1.0000e-03\n",
      "Epoch 54/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.5781 - val_sparse_categorical_accuracy: 0.8528 - lr: 1.0000e-03\n",
      "Epoch 55/100\n",
      "1562/1562 [============================>.] - ETA: 0s - loss: 0.2363 - sparse_categorical_accuracy: 0.9637\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2364 - sparse_categorical_accuracy: 0.9637 - val_loss: 0.5759 - val_sparse_categorical_accuracy: 0.8542 - lr: 1.0000e-03\n",
      "Epoch 56/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2304 - sparse_categorical_accuracy: 0.9655 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.8549 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2292 - sparse_categorical_accuracy: 0.9664 - val_loss: 0.5723 - val_sparse_categorical_accuracy: 0.8553 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2262 - sparse_categorical_accuracy: 0.9675 - val_loss: 0.5717 - val_sparse_categorical_accuracy: 0.8557 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.5719 - val_sparse_categorical_accuracy: 0.8551 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2269 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.5728 - val_sparse_categorical_accuracy: 0.8551 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2248 - sparse_categorical_accuracy: 0.9683 - val_loss: 0.5736 - val_sparse_categorical_accuracy: 0.8554 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2264 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.5731 - val_sparse_categorical_accuracy: 0.8554 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2249 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.8554 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.8552 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "1562/1562 [============================>.] - ETA: 0s - loss: 0.2250 - sparse_categorical_accuracy: 0.9676\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2250 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.8559 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.8557 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2250 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.8555 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2231 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.8565 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9690 - val_loss: 0.5736 - val_sparse_categorical_accuracy: 0.8562 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2229 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.5736 - val_sparse_categorical_accuracy: 0.8559 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.8551 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.9693 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.8553 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2241 - sparse_categorical_accuracy: 0.9683 - val_loss: 0.5741 - val_sparse_categorical_accuracy: 0.8552 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2247 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.5738 - val_sparse_categorical_accuracy: 0.8551 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "1563/1562 [==============================] - ETA: 0s - loss: 0.2237 - sparse_categorical_accuracy: 0.9687\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.8561 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2231 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.5747 - val_sparse_categorical_accuracy: 0.8560 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5727 - val_sparse_categorical_accuracy: 0.8552 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5724 - val_sparse_categorical_accuracy: 0.8554 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9699 - val_loss: 0.5749 - val_sparse_categorical_accuracy: 0.8547 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9681 - val_loss: 0.5733 - val_sparse_categorical_accuracy: 0.8550 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9693 - val_loss: 0.5730 - val_sparse_categorical_accuracy: 0.8559 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2247 - sparse_categorical_accuracy: 0.9683 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.8557 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2243 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.8557 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2242 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.8554 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.8549 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2235 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5730 - val_sparse_categorical_accuracy: 0.8557 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2227 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.5730 - val_sparse_categorical_accuracy: 0.8555 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2227 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.5731 - val_sparse_categorical_accuracy: 0.8556 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.8549 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.5735 - val_sparse_categorical_accuracy: 0.8549 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2233 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.5728 - val_sparse_categorical_accuracy: 0.8562 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2226 - sparse_categorical_accuracy: 0.9693 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.8551 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.5730 - val_sparse_categorical_accuracy: 0.8553 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2221 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.5747 - val_sparse_categorical_accuracy: 0.8555 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.8559 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2235 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.5731 - val_sparse_categorical_accuracy: 0.8553 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2241 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.8557 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2249 - sparse_categorical_accuracy: 0.9681 - val_loss: 0.5736 - val_sparse_categorical_accuracy: 0.8549 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2227 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.5739 - val_sparse_categorical_accuracy: 0.8552 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.5736 - val_sparse_categorical_accuracy: 0.8552 - lr: 1.0000e-06\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.5736 - sparse_categorical_accuracy: 0.8552\n",
      "\n",
      "End !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "lr = 0.1\n",
    "\n",
    "NAME = f\"Resnet8_scratch_with_callbacks\"\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir = f\"logs2/{NAME}\", \n",
    "                                                 histogram_freq = 1)\n",
    "\n",
    "\n",
    "student_scratch.compile(\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9),\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "        loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        )\n",
    "\n",
    "    # Train and evaluate on data.\n",
    "hist = student_scratch.fit(x_train, y_train, \n",
    "      batch_size = BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      steps_per_epoch = len(x_train)/BATCH_SIZE,\n",
    "      validation_data =(x_test, y_test),\n",
    "      workers =40,\n",
    "      use_multiprocessing= True,\n",
    "      callbacks = [lr_reduce2, tensorboard],\n",
    "      )\n",
    "\n",
    "\n",
    "student_scratch.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"End !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b3cc5",
   "metadata": {},
   "source": [
    "## Knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7877f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "A = [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "lr = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc06aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for a in A:\n",
    "    # Configuration du tensorboard\n",
    "    NAME = f\"Resnet8_kd_alpha_{a}_temp_{5}\"\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir = f\"logs2/{NAME}\", \n",
    "                                                 histogram_freq = 1)\n",
    "    \n",
    "    student_test = tf.keras.models.clone_model(student)\n",
    "\n",
    "    dist = Distiller(teacher, student_test)\n",
    "\n",
    "    dist.compile(\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9),\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "        distillation_loss_fn = tf.keras.losses.KLDivergence(),\n",
    "        student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        alpha = a,\n",
    "        temperature = 5)\n",
    "\n",
    "    # Train and evaluate on data.\n",
    "    hist = dist.fit(x_train, y_train, \n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          steps_per_epoch = len(x_train)/BATCH_SIZE,\n",
    "          validation_data =(x_test, y_test),\n",
    "          workers =40,\n",
    "          use_multiprocessing= True,\n",
    "          callbacks = [lr_reduce, tensorboard],\n",
    "          )\n",
    "\n",
    "\n",
    "    dist.evaluate(x_test, y_test)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\" =============== History Plot ===============\")\n",
    "    plot_hist_kd(hist, f\"Resnet8_KD_notebook_alpha{a}.png\")\n",
    "\n",
    "\n",
    "    print(\"Saving model \")\n",
    "    student.save(f\"Resnet8_KD_notebook_alpha{a}\")\n",
    "    print(\"Saving Done !\")\n",
    "\n",
    "    print(\"Saving Weights \")\n",
    "    student.save_weights(f\"w_resnet8_alpha_{a}.h5\")\n",
    "    print(\"Saving Done !\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"End !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784258b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
