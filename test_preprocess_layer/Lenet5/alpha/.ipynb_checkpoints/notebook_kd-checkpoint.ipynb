{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4976fd",
   "metadata": {},
   "source": [
    "## Bibilioth√®que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2da05cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf;\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from Distiller import Distiller_AdaIn, Distiller\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "seed = tf.random.set_seed(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59d199",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9ab2228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_hist_kd(hist, figname):\n",
    "    #History\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(hist.history['sparse_categorical_accuracy'], label = \"train accur\")\n",
    "    plt.plot(hist.history['val_sparse_categorical_accuracy'], label = \"Val accur\")\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(hist.history['student_loss'], label = \"student Loss\")\n",
    "    plt.plot(hist.history['val_student_loss'], label = \"Val loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Student Loss')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(figname)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8cf7b",
   "metadata": {},
   "source": [
    "## Loading cifar10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2339918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Data Loading ================\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "y_test shape: (10000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"================ Data Loading ================\")\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Data shapes\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac01f4",
   "metadata": {},
   "source": [
    "## Loading Resnet26 Teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a345a505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Loading teacher model ================\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer-0.layer-0._random_generator._generator._state_var\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer-0.layer-1._random_generator._generator._state_var\n",
      "Evaluation of Teacher model!\n",
      "313/313 [==============================] - 12s 35ms/step - loss: 0.5328 - sparse_categorical_accuracy: 0.9054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"================ Loading teacher model ================\")\n",
    "teacher = tf.keras.models.load_model(\"Resnet26_from_logits\");\n",
    "print(\"Evaluation of Teacher model!\")\n",
    "teacher.evaluate(x_test, y_test)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d738c",
   "metadata": {},
   "source": [
    "## Building a preprocessing routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fec9d02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ============== Adding preprocessing layers ===============\n"
     ]
    }
   ],
   "source": [
    "print(\" ============== Adding preprocessing layers ===============\")\n",
    "preprocessing = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomCrop(32, 32, seed= seed),\n",
    "    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed= seed),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66b092",
   "metadata": {},
   "source": [
    "## Building Lenet5 Student model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d168fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Building Student Network Lenet5 ! =============\n"
     ]
    }
   ],
   "source": [
    "print(\"============== Building Student Network Lenet5 ! =============\")\n",
    "\n",
    "student = tf.keras.Sequential([\n",
    "    preprocessing,\n",
    "    tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(32,32,3)),\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=2, padding=\"valid\"),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=2, padding=\"valid\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=120, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=84, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10)\n",
    "\n",
    "]);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3265cc",
   "metadata": {},
   "source": [
    "## Building callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e0c96cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_save = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/callback/callback_save\",\n",
    "    monitor='val_student_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    "    options=None,\n",
    "    initial_value_threshold=None,\n",
    ")\n",
    "\n",
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_student_loss',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    \n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.000001,\n",
    ")\n",
    "\n",
    "lr_reduce2 = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    \n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.000001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3776d",
   "metadata": {},
   "source": [
    "## Scratch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fc6294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_scratch = tf.keras.Sequential([\n",
    "    student,\n",
    "    tf.keras.layers.Activation(\"softmax\"),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a7d2f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1562/1562 [==============================] - 15s 10ms/step - loss: 1.9314 - sparse_categorical_accuracy: 0.2995 - val_loss: 1.6408 - val_sparse_categorical_accuracy: 0.3956 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.5648 - sparse_categorical_accuracy: 0.4395 - val_loss: 1.5233 - val_sparse_categorical_accuracy: 0.4450 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.4350 - sparse_categorical_accuracy: 0.4876 - val_loss: 1.4155 - val_sparse_categorical_accuracy: 0.4893 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.3526 - sparse_categorical_accuracy: 0.5165 - val_loss: 1.3915 - val_sparse_categorical_accuracy: 0.5131 - lr: 0.1000\n",
      "Epoch 5/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.2840 - sparse_categorical_accuracy: 0.5415 - val_loss: 1.3230 - val_sparse_categorical_accuracy: 0.5285 - lr: 0.1000\n",
      "Epoch 6/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.2299 - sparse_categorical_accuracy: 0.5636 - val_loss: 1.3600 - val_sparse_categorical_accuracy: 0.5168 - lr: 0.1000\n",
      "Epoch 7/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.1825 - sparse_categorical_accuracy: 0.5779 - val_loss: 1.3324 - val_sparse_categorical_accuracy: 0.5298 - lr: 0.1000\n",
      "Epoch 8/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.1381 - sparse_categorical_accuracy: 0.5959 - val_loss: 1.3030 - val_sparse_categorical_accuracy: 0.5459 - lr: 0.1000\n",
      "Epoch 9/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.0972 - sparse_categorical_accuracy: 0.6076 - val_loss: 1.5321 - val_sparse_categorical_accuracy: 0.4937 - lr: 0.1000\n",
      "Epoch 10/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.0662 - sparse_categorical_accuracy: 0.6204 - val_loss: 1.3658 - val_sparse_categorical_accuracy: 0.5303 - lr: 0.1000\n",
      "Epoch 11/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 1.0308 - sparse_categorical_accuracy: 0.6329 - val_loss: 1.3556 - val_sparse_categorical_accuracy: 0.5385 - lr: 0.1000\n",
      "Epoch 12/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.9980 - sparse_categorical_accuracy: 0.6418 - val_loss: 1.3703 - val_sparse_categorical_accuracy: 0.5373 - lr: 0.1000\n",
      "Epoch 13/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.9795 - sparse_categorical_accuracy: 0.6508 - val_loss: 1.4101 - val_sparse_categorical_accuracy: 0.5383 - lr: 0.1000\n",
      "Epoch 14/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.9509 - sparse_categorical_accuracy: 0.6601 - val_loss: 1.3516 - val_sparse_categorical_accuracy: 0.5615 - lr: 0.1000\n",
      "Epoch 15/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.9244 - sparse_categorical_accuracy: 0.6698 - val_loss: 1.3950 - val_sparse_categorical_accuracy: 0.5478 - lr: 0.1000\n",
      "Epoch 16/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.9023 - sparse_categorical_accuracy: 0.6755 - val_loss: 1.4389 - val_sparse_categorical_accuracy: 0.5410 - lr: 0.1000\n",
      "Epoch 17/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.8813 - sparse_categorical_accuracy: 0.6855 - val_loss: 1.3654 - val_sparse_categorical_accuracy: 0.5583 - lr: 0.1000\n",
      "Epoch 18/100\n",
      "1559/1562 [============================>.] - ETA: 0s - loss: 0.8625 - sparse_categorical_accuracy: 0.6919\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.8629 - sparse_categorical_accuracy: 0.6919 - val_loss: 1.4305 - val_sparse_categorical_accuracy: 0.5485 - lr: 0.1000\n",
      "Epoch 19/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.6328 - sparse_categorical_accuracy: 0.7733 - val_loss: 1.4010 - val_sparse_categorical_accuracy: 0.5856 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.5700 - sparse_categorical_accuracy: 0.7968 - val_loss: 1.4382 - val_sparse_categorical_accuracy: 0.5831 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.5399 - sparse_categorical_accuracy: 0.8082 - val_loss: 1.4659 - val_sparse_categorical_accuracy: 0.5847 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.5178 - sparse_categorical_accuracy: 0.8161 - val_loss: 1.5095 - val_sparse_categorical_accuracy: 0.5818 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.4996 - sparse_categorical_accuracy: 0.8235 - val_loss: 1.5293 - val_sparse_categorical_accuracy: 0.5818 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.4831 - sparse_categorical_accuracy: 0.8292 - val_loss: 1.5745 - val_sparse_categorical_accuracy: 0.5831 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.4687 - sparse_categorical_accuracy: 0.8348 - val_loss: 1.6115 - val_sparse_categorical_accuracy: 0.5800 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1562/1562 [==============================] - 14s 9ms/step - loss: 0.4551 - sparse_categorical_accuracy: 0.8395 - val_loss: 1.6350 - val_sparse_categorical_accuracy: 0.5811 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8461 - val_loss: 1.6645 - val_sparse_categorical_accuracy: 0.5803 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.4310 - sparse_categorical_accuracy: 0.8507\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.4310 - sparse_categorical_accuracy: 0.8507 - val_loss: 1.7095 - val_sparse_categorical_accuracy: 0.5776 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3952 - sparse_categorical_accuracy: 0.8676 - val_loss: 1.7142 - val_sparse_categorical_accuracy: 0.5772 - lr: 1.0000e-03\n",
      "Epoch 30/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3908 - sparse_categorical_accuracy: 0.8688 - val_loss: 1.7254 - val_sparse_categorical_accuracy: 0.5781 - lr: 1.0000e-03\n",
      "Epoch 31/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3887 - sparse_categorical_accuracy: 0.8704 - val_loss: 1.7313 - val_sparse_categorical_accuracy: 0.5770 - lr: 1.0000e-03\n",
      "Epoch 32/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3869 - sparse_categorical_accuracy: 0.8700 - val_loss: 1.7388 - val_sparse_categorical_accuracy: 0.5764 - lr: 1.0000e-03\n",
      "Epoch 33/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3853 - sparse_categorical_accuracy: 0.8712 - val_loss: 1.7466 - val_sparse_categorical_accuracy: 0.5779 - lr: 1.0000e-03\n",
      "Epoch 34/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3838 - sparse_categorical_accuracy: 0.8712 - val_loss: 1.7493 - val_sparse_categorical_accuracy: 0.5770 - lr: 1.0000e-03\n",
      "Epoch 35/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3824 - sparse_categorical_accuracy: 0.8719 - val_loss: 1.7555 - val_sparse_categorical_accuracy: 0.5777 - lr: 1.0000e-03\n",
      "Epoch 36/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3809 - sparse_categorical_accuracy: 0.8726 - val_loss: 1.7598 - val_sparse_categorical_accuracy: 0.5777 - lr: 1.0000e-03\n",
      "Epoch 37/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3796 - sparse_categorical_accuracy: 0.8730 - val_loss: 1.7656 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-03\n",
      "Epoch 38/100\n",
      "1557/1562 [============================>.] - ETA: 0s - loss: 0.3781 - sparse_categorical_accuracy: 0.8738\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3781 - sparse_categorical_accuracy: 0.8738 - val_loss: 1.7753 - val_sparse_categorical_accuracy: 0.5765 - lr: 1.0000e-03\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3742 - sparse_categorical_accuracy: 0.8760 - val_loss: 1.7746 - val_sparse_categorical_accuracy: 0.5770 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3738 - sparse_categorical_accuracy: 0.8759 - val_loss: 1.7743 - val_sparse_categorical_accuracy: 0.5765 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3737 - sparse_categorical_accuracy: 0.8761 - val_loss: 1.7746 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3735 - sparse_categorical_accuracy: 0.8762 - val_loss: 1.7754 - val_sparse_categorical_accuracy: 0.5764 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3733 - sparse_categorical_accuracy: 0.8760 - val_loss: 1.7756 - val_sparse_categorical_accuracy: 0.5765 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3732 - sparse_categorical_accuracy: 0.8759 - val_loss: 1.7762 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3730 - sparse_categorical_accuracy: 0.8761 - val_loss: 1.7767 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3729 - sparse_categorical_accuracy: 0.8762 - val_loss: 1.7777 - val_sparse_categorical_accuracy: 0.5765 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8764 - val_loss: 1.7781 - val_sparse_categorical_accuracy: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "1559/1562 [============================>.] - ETA: 0s - loss: 0.3726 - sparse_categorical_accuracy: 0.8766\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3726 - sparse_categorical_accuracy: 0.8766 - val_loss: 1.7782 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3722 - sparse_categorical_accuracy: 0.8766 - val_loss: 1.7783 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3722 - sparse_categorical_accuracy: 0.8766 - val_loss: 1.7784 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8766 - val_loss: 1.7785 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7786 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7787 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8766 - val_loss: 1.7788 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7788 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7789 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3721 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "1559/1562 [============================>.] - ETA: 0s - loss: 0.3720 - sparse_categorical_accuracy: 0.8767\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 65/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 66/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 67/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 68/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 69/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 73/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5768 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-06\n",
      "Epoch 75/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-06\n",
      "Epoch 76/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8767 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5767 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "1562/1562 [==============================] - 15s 9ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8768 - val_loss: 1.7790 - val_sparse_categorical_accuracy: 0.5766 - lr: 1.0000e-06\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.7790 - sparse_categorical_accuracy: 0.5766\n",
      "\n",
      "End !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "lr = 0.1\n",
    "\n",
    "NAME = f\"Lenet5_scratch\"\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir = f\"logs/{NAME}\", \n",
    "                                                 histogram_freq = 1)\n",
    "\n",
    "\n",
    "student_scratch.compile(\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "        loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        )\n",
    "\n",
    "    # Train and evaluate on data.\n",
    "hist = student_scratch.fit(x_train, y_train, \n",
    "      batch_size = BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      steps_per_epoch = len(x_train)/BATCH_SIZE,\n",
    "      validation_data =(x_test, y_test),\n",
    "      workers =40,\n",
    "      use_multiprocessing= True,\n",
    "      callbacks = [lr_reduce2, tensorboard],\n",
    "      )\n",
    "\n",
    "\n",
    "student_scratch.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"End !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b3cc5",
   "metadata": {},
   "source": [
    "## Knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fb7877f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "A = [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "lr = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afc06aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1562/1562 [==============================] - 64s 40ms/step - sparse_categorical_accuracy: 0.2920 - student_loss: 2.3450 - Dist_loss: 1.5212 - loss: 1.6035 - val_sparse_categorical_accuracy: 0.3674 - val_student_loss: 2.5987 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.4199 - student_loss: 2.2973 - Dist_loss: 1.2391 - loss: 1.3449 - val_sparse_categorical_accuracy: 0.4402 - val_student_loss: 1.5202 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.4742 - student_loss: 2.2042 - Dist_loss: 1.1124 - loss: 1.2216 - val_sparse_categorical_accuracy: 0.4634 - val_student_loss: 1.5854 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.5059 - student_loss: 2.1305 - Dist_loss: 1.0352 - loss: 1.1447 - val_sparse_categorical_accuracy: 0.4759 - val_student_loss: 1.4403 - lr: 0.1000\n",
      "Epoch 5/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.5291 - student_loss: 2.0609 - Dist_loss: 0.9808 - loss: 1.0888 - val_sparse_categorical_accuracy: 0.5121 - val_student_loss: 1.5001 - lr: 0.1000\n",
      "Epoch 6/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.5509 - student_loss: 2.0060 - Dist_loss: 0.9378 - loss: 1.0446 - val_sparse_categorical_accuracy: 0.5220 - val_student_loss: 2.5208 - lr: 0.1000\n",
      "Epoch 7/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.5679 - student_loss: 1.9578 - Dist_loss: 0.9036 - loss: 1.0090 - val_sparse_categorical_accuracy: 0.4848 - val_student_loss: 2.4186 - lr: 0.1000\n",
      "Epoch 8/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.5806 - student_loss: 1.9021 - Dist_loss: 0.8684 - loss: 0.9718 - val_sparse_categorical_accuracy: 0.5267 - val_student_loss: 2.5240 - lr: 0.1000\n",
      "Epoch 9/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.5949 - student_loss: 1.8575 - Dist_loss: 0.8417 - loss: 0.9432 - val_sparse_categorical_accuracy: 0.5296 - val_student_loss: 2.5871 - lr: 0.1000\n",
      "Epoch 10/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.6076 - student_loss: 1.8055 - Dist_loss: 0.8116 - loss: 0.9110 - val_sparse_categorical_accuracy: 0.5443 - val_student_loss: 1.5038 - lr: 0.1000\n",
      "Epoch 11/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.6199 - student_loss: 1.7622 - Dist_loss: 0.7879 - loss: 0.8853 - val_sparse_categorical_accuracy: 0.5641 - val_student_loss: 1.4886 - lr: 0.1000\n",
      "Epoch 12/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.6300 - student_loss: 1.7125 - Dist_loss: 0.7633 - loss: 0.8582 - val_sparse_categorical_accuracy: 0.5346 - val_student_loss: 1.4943 - lr: 0.1000\n",
      "Epoch 13/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.6402 - student_loss: 1.6677 - Dist_loss: 0.7444 - loss: 0.8368 - val_sparse_categorical_accuracy: 0.5673 - val_student_loss: 1.4894 - lr: 0.1000\n",
      "Epoch 14/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.6483 - student_loss: 1.6298 - Dist_loss: 0.7273 - loss: 0.8176 - val_sparse_categorical_accuracy: 0.5656 - val_student_loss: 1.3991 - lr: 0.1000\n",
      "Epoch 15/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.6586 - student_loss: 1.5840 - Dist_loss: 0.7066 - loss: 0.7943 - val_sparse_categorical_accuracy: 0.4856 - val_student_loss: 3.5087 - lr: 0.1000\n",
      "Epoch 16/100\n",
      "1562/1562 [==============================] - 61s 39ms/step - sparse_categorical_accuracy: 0.6666 - student_loss: 1.5410 - Dist_loss: 0.6876 - loss: 0.7729 - val_sparse_categorical_accuracy: 0.5802 - val_student_loss: 1.5025 - lr: 0.1000\n",
      "Epoch 17/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.6760 - student_loss: 1.4997 - Dist_loss: 0.6715 - loss: 0.7543 - val_sparse_categorical_accuracy: 0.5594 - val_student_loss: 1.4536 - lr: 0.1000\n",
      "Epoch 18/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.6822 - student_loss: 1.4586 - Dist_loss: 0.6561 - loss: 0.7363 - val_sparse_categorical_accuracy: 0.5689 - val_student_loss: 1.5349 - lr: 0.1000\n",
      "Epoch 19/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.6917 - student_loss: 1.4176 - Dist_loss: 0.6398 - loss: 0.7176 - val_sparse_categorical_accuracy: 0.5598 - val_student_loss: 1.5510 - lr: 0.1000\n",
      "Epoch 20/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.6982 - student_loss: 1.3881 - Dist_loss: 0.6277 - loss: 0.7038 - val_sparse_categorical_accuracy: 0.5690 - val_student_loss: 1.5034 - lr: 0.1000\n",
      "Epoch 21/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.7030 - student_loss: 1.3580 - Dist_loss: 0.6163 - loss: 0.6905 - val_sparse_categorical_accuracy: 0.5631 - val_student_loss: 1.4674 - lr: 0.1000\n",
      "Epoch 22/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.7135 - student_loss: 1.3146 - Dist_loss: 0.6001 - loss: 0.6716 - val_sparse_categorical_accuracy: 0.5753 - val_student_loss: 1.4372 - lr: 0.1000\n",
      "Epoch 23/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.7157 - student_loss: 1.2861 - Dist_loss: 0.5908 - loss: 0.6604 - val_sparse_categorical_accuracy: 0.5791 - val_student_loss: 1.4017 - lr: 0.1000\n",
      "Epoch 24/100\n",
      "1563/1562 [==============================] - ETA: 0s - sparse_categorical_accuracy: 0.7229 - student_loss: 1.2600 - Dist_loss: 0.5811 - loss: 0.6490\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.7229 - student_loss: 1.2600 - Dist_loss: 0.5810 - loss: 0.6489 - val_sparse_categorical_accuracy: 0.5822 - val_student_loss: 1.4785 - lr: 0.1000\n",
      "Epoch 25/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.7931 - student_loss: 0.8409 - Dist_loss: 0.4688 - loss: 0.5060 - val_sparse_categorical_accuracy: 0.6010 - val_student_loss: 1.4546 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8084 - student_loss: 0.7736 - Dist_loss: 0.4444 - loss: 0.4773 - val_sparse_categorical_accuracy: 0.5983 - val_student_loss: 1.4512 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.8154 - student_loss: 0.7440 - Dist_loss: 0.4352 - loss: 0.4661 - val_sparse_categorical_accuracy: 0.6018 - val_student_loss: 1.4384 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8198 - student_loss: 0.7212 - Dist_loss: 0.4282 - loss: 0.4575 - val_sparse_categorical_accuracy: 0.5998 - val_student_loss: 1.4758 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.8261 - student_loss: 0.7011 - Dist_loss: 0.4227 - loss: 0.4506 - val_sparse_categorical_accuracy: 0.6002 - val_student_loss: 1.4782 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.8288 - student_loss: 0.6847 - Dist_loss: 0.4182 - loss: 0.4449 - val_sparse_categorical_accuracy: 0.5973 - val_student_loss: 1.4498 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.8312 - student_loss: 0.6709 - Dist_loss: 0.4140 - loss: 0.4397 - val_sparse_categorical_accuracy: 0.5966 - val_student_loss: 1.4899 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.8339 - student_loss: 0.6568 - Dist_loss: 0.4107 - loss: 0.4353 - val_sparse_categorical_accuracy: 0.5967 - val_student_loss: 1.4834 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8367 - student_loss: 0.6429 - Dist_loss: 0.4069 - loss: 0.4305 - val_sparse_categorical_accuracy: 0.5983 - val_student_loss: 1.4644 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "1563/1562 [==============================] - ETA: 0s - sparse_categorical_accuracy: 0.8400 - student_loss: 0.6329 - Dist_loss: 0.4036 - loss: 0.4265\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8400 - student_loss: 0.6331 - Dist_loss: 0.4036 - loss: 0.4265 - val_sparse_categorical_accuracy: 0.5979 - val_student_loss: 1.4525 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.8502 - student_loss: 0.5798 - Dist_loss: 0.3923 - loss: 0.4111 - val_sparse_categorical_accuracy: 0.6000 - val_student_loss: 1.4802 - lr: 1.0000e-03\n",
      "Epoch 36/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8515 - student_loss: 0.5775 - Dist_loss: 0.3908 - loss: 0.4095 - val_sparse_categorical_accuracy: 0.5985 - val_student_loss: 1.4687 - lr: 1.0000e-03\n",
      "Epoch 37/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8521 - student_loss: 0.5761 - Dist_loss: 0.3902 - loss: 0.4088 - val_sparse_categorical_accuracy: 0.6004 - val_student_loss: 1.4748 - lr: 1.0000e-03\n",
      "Epoch 38/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8525 - student_loss: 0.5748 - Dist_loss: 0.3899 - loss: 0.4083 - val_sparse_categorical_accuracy: 0.6002 - val_student_loss: 1.4788 - lr: 1.0000e-03\n",
      "Epoch 39/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8526 - student_loss: 0.5737 - Dist_loss: 0.3894 - loss: 0.4078 - val_sparse_categorical_accuracy: 0.5992 - val_student_loss: 1.4691 - lr: 1.0000e-03\n",
      "Epoch 40/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8529 - student_loss: 0.5731 - Dist_loss: 0.3891 - loss: 0.4075 - val_sparse_categorical_accuracy: 0.5985 - val_student_loss: 1.4749 - lr: 1.0000e-03\n",
      "Epoch 41/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8529 - student_loss: 0.5708 - Dist_loss: 0.3887 - loss: 0.4069 - val_sparse_categorical_accuracy: 0.5991 - val_student_loss: 1.4729 - lr: 1.0000e-03\n",
      "Epoch 42/100\n",
      "1562/1562 [==============================] - 62s 39ms/step - sparse_categorical_accuracy: 0.8536 - student_loss: 0.5701 - Dist_loss: 0.3884 - loss: 0.4066 - val_sparse_categorical_accuracy: 0.5978 - val_student_loss: 1.4680 - lr: 1.0000e-03\n",
      "Epoch 43/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8535 - student_loss: 0.5687 - Dist_loss: 0.3880 - loss: 0.4061 - val_sparse_categorical_accuracy: 0.5983 - val_student_loss: 1.4713 - lr: 1.0000e-03\n",
      "Epoch 44/100\n",
      "1563/1562 [==============================] - ETA: 0s - sparse_categorical_accuracy: 0.8542 - student_loss: 0.5674 - Dist_loss: 0.3876 - loss: 0.4056\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8542 - student_loss: 0.5673 - Dist_loss: 0.3876 - loss: 0.4055 - val_sparse_categorical_accuracy: 0.5976 - val_student_loss: 1.4679 - lr: 1.0000e-03\n",
      "Epoch 45/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8551 - student_loss: 0.5612 - Dist_loss: 0.3864 - loss: 0.4039 - val_sparse_categorical_accuracy: 0.5982 - val_student_loss: 1.4703 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8550 - student_loss: 0.5613 - Dist_loss: 0.3862 - loss: 0.4037 - val_sparse_categorical_accuracy: 0.5982 - val_student_loss: 1.4710 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8552 - student_loss: 0.5614 - Dist_loss: 0.3863 - loss: 0.4038 - val_sparse_categorical_accuracy: 0.5991 - val_student_loss: 1.4713 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8551 - student_loss: 0.5615 - Dist_loss: 0.3864 - loss: 0.4039 - val_sparse_categorical_accuracy: 0.5982 - val_student_loss: 1.4715 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8552 - student_loss: 0.5609 - Dist_loss: 0.3862 - loss: 0.4037 - val_sparse_categorical_accuracy: 0.5983 - val_student_loss: 1.4713 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8552 - student_loss: 0.5617 - Dist_loss: 0.3862 - loss: 0.4037 - val_sparse_categorical_accuracy: 0.5981 - val_student_loss: 1.4725 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8552 - student_loss: 0.5604 - Dist_loss: 0.3860 - loss: 0.4034 - val_sparse_categorical_accuracy: 0.5984 - val_student_loss: 1.4722 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8552 - student_loss: 0.5600 - Dist_loss: 0.3859 - loss: 0.4033 - val_sparse_categorical_accuracy: 0.5980 - val_student_loss: 1.4722 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "1562/1562 [==============================] - 62s 40ms/step - sparse_categorical_accuracy: 0.8555 - student_loss: 0.5601 - Dist_loss: 0.3861 - loss: 0.4035 - val_sparse_categorical_accuracy: 0.5977 - val_student_loss: 1.4723 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "1063/1562 [===================>..........] - ETA: 19s - sparse_categorical_accuracy: 0.8555 - student_loss: 0.5592 - Dist_loss: 0.3861 - loss: 0.4034"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m dist\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     12\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlr),\n\u001b[1;32m     13\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy()],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m a,\n\u001b[1;32m     17\u001b[0m     temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train and evaluate on data.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlr_reduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m dist\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/callbacks.py:1107\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m-> 1107\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/generic_utils.py:976\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    973\u001b[0m     info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    975\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[0;32m--> 976\u001b[0m   \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m   message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/io_utils.py:38\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m   sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message)\n\u001b[0;32m---> 38\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jup/lib/python3.9/site-packages/ipykernel/iostream.py:468\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    469\u001b[0m             \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    470\u001b[0m             \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    471\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/jup/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/jup/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for a in A:\n",
    "    # Configuration du tensorboard\n",
    "    NAME = f\"Lenet5_kd_alpha_{a}_temp_{5}\"\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir = f\"logs/{NAME}\", \n",
    "                                                 histogram_freq = 1)\n",
    "    \n",
    "    student_test = tf.keras.models.clone_model(student)\n",
    "\n",
    "    dist = Distiller(teacher, student_test)\n",
    "\n",
    "    dist.compile(\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "        distillation_loss_fn = tf.keras.losses.KLDivergence(),\n",
    "        student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        alpha = a,\n",
    "        temperature = 5)\n",
    "\n",
    "    # Train and evaluate on data.\n",
    "    hist = dist.fit(x_train, y_train, \n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          steps_per_epoch = len(x_train)/BATCH_SIZE,\n",
    "          validation_data =(x_test, y_test),\n",
    "          workers =40,\n",
    "          use_multiprocessing= True,\n",
    "          callbacks = [lr_reduce, tensorboard],\n",
    "          )\n",
    "\n",
    "\n",
    "    dist.evaluate(x_test, y_test)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\" =============== History Plot ===============\")\n",
    "    plot_hist_kd(hist, f\"Lenet5_KD_alpha{a}.png\")\n",
    "\n",
    "\n",
    "    print(\"Saving model \")\n",
    "    student_test.save(f\"Lenet5_KD_alpha{a}\")\n",
    "    print(\"Saving Done !\")\n",
    "\n",
    "    print(\"Saving Weights \")\n",
    "    student_test.save_weights(f\"w_Lenet5_alpha_{a}.h5\")\n",
    "    print(\"Saving Done !\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"End !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784258b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
